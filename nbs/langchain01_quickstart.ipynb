{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbff542",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a92db5",
   "metadata": {},
   "source": [
    "quickstart: https://python.langchain.com/docs/get_started/quickstart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f27b62-539b-4f09-9fe7-3877dafaa1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from configparser import ConfigParser\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "openai_api_key = config['LangChain']['openai_api_key']\n",
    "llm = ChatOpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2739dd55-1823-4704-9605-ac73e8ad7965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing by providing a platform for creating and running automated tests for software applications. It can assist in generating test scripts, executing tests, analyzing test results, and reporting any issues found during testing. Langsmith can also help in creating test cases based on requirements and specifications, and can assist in managing test data and test environments. Overall, Langsmith can streamline the testing process and help improve the efficiency and effectiveness of testing activities.', response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 15, 'total_tokens': 104}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_d9767fc5b9', 'finish_reason': 'stop', 'logprobs': None}, id='run-e6b86f99-6c9d-4160-bc83-eeeb149bad6c-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('how can langsmith help with testing?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa95fc4-ecc2-4bfe-8281-9e1c391e62c1",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "Guide its response with a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2663d195-d807-4a7c-9b3f-7c7c9d8a0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', ' you are world class technical writer'),\n",
    "    ('user','{input}')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d053480",
   "metadata": {},
   "source": [
    "Now combine these into a simple LLM chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a262a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40c2539",
   "metadata": {},
   "source": [
    "We can now invoke it and ask the same question. It still won't know the answer, but it should response with better tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ebaab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing in a variety of ways, thanks to its advanced language processing capabilities. Here are some ways in which Langsmith can be beneficial for testing:\\n\\n1. Automated Test Case Generation: Langsmith can be used to automatically generate test cases based on the requirements and specifications provided. By analyzing the language used in the requirements documents, Langsmith can create comprehensive test cases that cover all possible scenarios.\\n\\n2. Natural Language Testing: Langsmith can be used to perform natural language testing to verify that the software behaves as expected when interacting with users. This can help ensure that the software is user-friendly and that it responds appropriately to user inputs.\\n\\n3. Code Analysis: Langsmith can analyze code written in different programming languages to identify potential bugs, security vulnerabilities, or performance issues. This can help improve the quality of the software and reduce the likelihood of defects in the final product.\\n\\n4. Test Data Generation: Langsmith can be used to generate test data for different test scenarios. By analyzing the requirements and specifications, Langsmith can create realistic and diverse test data sets that can be used to validate the software under different conditions.\\n\\n5. Test Result Analysis: Langsmith can analyze test results to identify patterns, trends, or anomalies that may indicate potential issues in the software. This can help testers and developers quickly identify and address any problems that arise during testing.\\n\\nOverall, Langsmith can be a valuable tool for testing by leveraging its language processing capabilities to automate various testing tasks, improve test coverage, and enhance the overall quality of the software being tested.', response_metadata={'token_usage': {'completion_tokens': 310, 'prompt_tokens': 25, 'total_tokens': 335}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-e4e6c294-e36f-43ba-85c5-2b92413f224f-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'how can langsmith help with testing?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e479d6",
   "metadata": {},
   "source": [
    "## Output Parser\n",
    "However, it's often much more convenient to work with strings. Let's add a simple output parser to convert the chat message to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9281df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f1c38",
   "metadata": {},
   "source": [
    "Now add this to the previous chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8699dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "839eeb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith, a specialized testing tool, can greatly assist in the testing process by providing various features and functionalities that help streamline and optimize the testing efforts. Here are several ways in which Langsmith can help with testing:\\n\\n1. Test Automation: Langsmith offers automated testing capabilities that enable testers to automate the execution of test cases, saving time and effort in manual testing. This can help in running tests repeatedly and consistently, ensuring thorough test coverage.\\n\\n2. Test Case Management: Langsmith provides a centralized platform for managing test cases, test plans, and test results. Testers can create, organize, and prioritize test cases, as well as track the execution status and results of tests.\\n\\n3. Test Data Management: Langsmith facilitates the management of test data by providing tools for generating, importing, and manipulating test data sets. This helps in ensuring that tests are executed with relevant and accurate data.\\n\\n4. Integration with CI/CD Pipelines: Langsmith can integrate with continuous integration and continuous deployment (CI/CD) pipelines, allowing for seamless execution of tests as part of the software development process. This helps in identifying issues early in the development lifecycle.\\n\\n5. Reporting and Analytics: Langsmith offers reporting and analytics capabilities that provide insights into test execution results, test coverage, and defect trends. Testers can generate reports and dashboards to track testing progress and identify areas for improvement.\\n\\n6. Collaboration and Communication: Langsmith facilitates collaboration among testing teams by enabling testers to share test artifacts, communicate test-related information, and collaborate on testing activities. This promotes teamwork and enhances efficiency in testing.\\n\\n7. Customization and Extensibility: Langsmith can be customized and extended to meet specific testing requirements and integrate with other tools and systems. Testers can tailor the tool to suit their testing processes and workflows, enhancing its utility and effectiveness.\\n\\nOverall, Langsmith can help in improving the efficiency, accuracy, and effectiveness of testing activities by providing a comprehensive suite of testing capabilities and tools. It empowers testers to conduct thorough and reliable testing, ultimately contributing to the quality and reliability of the software being developed.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'how can langsmith help with testing?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c148a8",
   "metadata": {},
   "source": [
    "# Model I/O\n",
    "https://python.langchain.com/docs/modules/model_io/#prompt-templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec08086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = OpenAI()\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", api_key=openai_api_key)\n",
    "llm = ChatOpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30b5fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: content='Rainbow Footwear' response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 22, 'total_tokens': 26}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None} id='run-1062dd94-9f0d-4f81-8dda-a7030e3b7b56-0'\n",
      "LLM: content='RainbowFootwear' response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 22, 'total_tokens': 26}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_d9767fc5b9', 'finish_reason': 'stop', 'logprobs': None} id='run-679f0df8-fc5d-4c32-89a1-9bc7bd66c430-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "print(f\"LLM: {llm.invoke(text)}\")\n",
    "\n",
    "print(f\"LLM: {chat_model.invoke(messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8dec7",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "https://python.langchain.com/docs/modules/model_io/#prompt-templates\n",
    "\n",
    "Most LLM applications do not pass user input directly into an LLM. Usually they will add the user input to a larger piece of text, called a prompt template, that provides additional context on the specific task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fff2179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is a good name for a company that makes colorful socks?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template('what is a good name for a company that makes {product}?')\n",
    "prompt.format(product='colorful socks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b3033df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a helpful assistant that translates English to French.'),\n",
       " HumanMessage(content='I love programming.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = 'you are a helpful assistant that translates {input_language} to {output_language}.'\n",
    "human_template = '{text}'\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', template),\n",
    "    ('human', human_template),\n",
    "])\n",
    "\n",
    "chat_prompt.format_messages(input_language='English', output_language='French', text='I love programming.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae1359",
   "metadata": {},
   "source": [
    "## Output parsers\n",
    "https://python.langchain.com/docs/modules/model_io/#output-parsers\n",
    "\n",
    "OutputParsers convert the raw output of a language model into a format that can be used downstream. There are a few main types of OutputParsers, including:\n",
    "\n",
    "Convert text from LLM into structured information (e.g. JSON)\n",
    "Convert a ChatMessage into just a string\n",
    "Convert the extra information returned from a call besides the message (like OpenAI function invocation) into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "920132b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "output_parser.parse('hi, bye')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a37052",
   "metadata": {},
   "source": [
    "## Composising with LCEL\n",
    "We can now combine all these into one chain. This chain will take input variables, pass those to a prompt template to create a prompt, pass the prompt to a language model, and then pass the output through an (optional) output parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd6a20df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'green', 'yellow', 'purple']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Generate a list of 5 {text}.\\n\\n{format_instructions}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(template)\n",
    "chat_prompt = chat_prompt.partial(format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "chain = chat_prompt | chat_model | output_parser\n",
    "chain.invoke({'text':'colors'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649085fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
